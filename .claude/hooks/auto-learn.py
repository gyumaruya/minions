#!/usr/bin/env python3
"""
Hook: Auto-learn from user interactions.

Detects learning opportunities from user prompts:
- Corrections: ã€Œã€œã«ã—ã¦ã€ã€Œé•ã†ã€ã€Œã€œã˜ã‚ƒãªã„ã€
- Preferences: ã€Œã€œãŒã„ã„ã€ã€Œã€œã‚’ä½¿ã£ã¦ã€
- Workflows: ã€Œã„ã¤ã‚‚ã€œã€ã€Œæ¯å›ã€œã€

Saves learnings to memory for self-improvement.
"""

import json
import re
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

# Correction patterns (Japanese)
CORRECTION_PATTERNS = [
    (r"(.+)ã«ã—ã¦", "user_correction"),
    (r"(.+)ã«å¤‰ãˆã¦", "user_correction"),
    (r"(.+)ã¯é•ã†", "user_correction"),
    (r"(.+)ã˜ã‚ƒãªã„", "user_correction"),
    (r"(.+)ã§ã¯ãªã(.+)", "user_correction"),
    (r"(.+)ã‚ˆã‚Š(.+)ãŒã„ã„", "user_preference"),
    (r"(.+)ã‚’ä½¿ã£ã¦", "user_preference"),
    (r"(.+)ã‚’ä½¿ã‚ãªã„ã§", "user_preference"),
    (r"ã„ã¤ã‚‚(.+)", "workflow"),
    (r"æ¯å›(.+)", "workflow"),
    (r"å¸¸ã«(.+)", "workflow"),
    (r"è¦šãˆã¦[ï¼š:]\s*(.+)", "explicit_learn"),
    (r"è¨˜æ†¶ã—ã¦[ï¼š:]\s*(.+)", "explicit_learn"),
]

# Memory type mapping
TRIGGER_TO_TYPE = {
    "user_correction": "preference",
    "user_preference": "preference",
    "workflow": "workflow",
    "explicit_learn": "preference",
}


def detect_learning(text: str) -> list[tuple[str, str, str]]:
    """
    Detect learning opportunities in user text.

    Returns list of (content, trigger_type, memory_type) tuples.
    """
    learnings = []

    # Skip questions (ends with ? or ã®ï¼Ÿ etc.)
    if re.search(r"[?ï¼Ÿ]$|ã®[?ï¼Ÿ]$|ã‹ãª[?ï¼Ÿ]?$|ã ã„[?ï¼Ÿ]?$", text.strip()):
        return learnings

    # Skip too long text (likely conversational, not a directive)
    if len(text) > 50:
        return learnings

    for pattern, trigger in CORRECTION_PATTERNS:
        match = re.search(pattern, text)
        if match:
            # Extract the full match as learning content
            content = match.group(0)
            memory_type = TRIGGER_TO_TYPE.get(trigger, "preference")
            learnings.append((content, trigger, memory_type))

    return learnings


def save_learning(content: str, memory_type: str, trigger: str) -> bool:
    """Save a learning to memory directly."""
    try:
        from minions.memory import AgentType, MemoryBroker, MemoryScope, MemoryType

        broker = MemoryBroker(enable_mem0=False)
        broker.add(
            content=content,
            memory_type=MemoryType(memory_type),
            scope=MemoryScope.USER,
            source_agent=AgentType.CLAUDE,
            context=f"auto-learn: {trigger}",
        )
        return True
    except Exception:
        return False


def main() -> None:
    """Main hook entry point."""
    try:
        hook_input = json.load(sys.stdin)
    except (json.JSONDecodeError, Exception):
        sys.exit(0)

    # Get user prompt
    user_message = hook_input.get("prompt", "")

    if not user_message:
        sys.exit(0)

    # Detect learnings
    learnings = detect_learning(user_message)

    # Save detected learnings (fire and forget)
    saved = 0
    for content, trigger, memory_type in learnings:
        if save_learning(content, memory_type, trigger):
            saved += 1

    # Add system message about learned content
    if saved > 0:
        json.dump(
            {
                "hookSpecificOutput": {
                    "hookEventName": "UserPromptSubmit",
                    "additionalContext": f"ğŸ’¡ {saved} ä»¶ã®å­¦ç¿’ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚",
                }
            },
            sys.stdout,
            ensure_ascii=False,
        )

    sys.exit(0)


if __name__ == "__main__":
    main()
